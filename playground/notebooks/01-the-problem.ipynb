{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# 01 - The Problem: Why Casys MCP Gateway Exists\n",
    "\n",
    "Before learning how the gateway works, let's **experience the problems it solves**.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After this notebook, you will:\n",
    "\n",
    "- [ ] See how tool schemas consume context tokens\n",
    "- [ ] Measure the latency cost of sequential execution\n",
    "- [ ] Understand why these problems limit MCP adoption\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Problem 1: The Context Explosion\n",
    "\n",
    "Every MCP tool has a **schema** that describes:\n",
    "\n",
    "- What the tool does (description)\n",
    "- What inputs it needs (parameters)\n",
    "- What it returns (output schema)\n",
    "\n",
    "When you connect an MCP server, **ALL schemas are loaded** into the LLM context.\n",
    "\n",
    "Let's simulate what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Server Context Consumption\n",
      "==================================================\n",
      "\n",
      "github       15 tools Ã— 800 tokens = 12,000 tokens (6.0%)\n",
      "filesystem    8 tools Ã— 600 tokens =  4,800 tokens (2.4%)\n",
      "database     12 tools Ã— 900 tokens = 10,800 tokens (5.4%)\n",
      "playwright   20 tools Ã— 750 tokens = 15,000 tokens (7.5%)\n",
      "slack        10 tools Ã— 700 tokens =  7,000 tokens (3.5%)\n",
      "notion       14 tools Ã— 850 tokens = 11,900 tokens (5.9%)\n",
      "jira         16 tools Ã— 820 tokens = 13,120 tokens (6.6%)\n",
      "serena       25 tools Ã— 650 tokens = 16,250 tokens (8.1%)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "TOTAL:       120 tools                   90,870 tokens (45.4%)\n",
      "\n",
      "âš ï¸  45.4% of your context window is consumed BEFORE you even start talking!\n"
     ]
    }
   ],
   "source": [
    "// Simulate MCP tool schemas (realistic sizes)\n",
    "const mcpServers = {\n",
    "  github: {\n",
    "    tools: 15,\n",
    "    avgTokensPerTool: 800,\n",
    "    examples: [\"create_issue\", \"list_commits\", \"create_pr\", \"search_code\"],\n",
    "  },\n",
    "  filesystem: {\n",
    "    tools: 8,\n",
    "    avgTokensPerTool: 600,\n",
    "    examples: [\"read_file\", \"write_file\", \"list_directory\", \"search_files\"],\n",
    "  },\n",
    "  database: {\n",
    "    tools: 12,\n",
    "    avgTokensPerTool: 900,\n",
    "    examples: [\"query\", \"insert\", \"update\", \"create_table\"],\n",
    "  },\n",
    "  playwright: {\n",
    "    tools: 20,\n",
    "    avgTokensPerTool: 750,\n",
    "    examples: [\"navigate\", \"click\", \"screenshot\", \"fill_form\"],\n",
    "  },\n",
    "  slack: {\n",
    "    tools: 10,\n",
    "    avgTokensPerTool: 700,\n",
    "    examples: [\"send_message\", \"search_messages\", \"list_channels\"],\n",
    "  },\n",
    "  notion: {\n",
    "    tools: 14,\n",
    "    avgTokensPerTool: 850,\n",
    "    examples: [\"create_page\", \"query_database\", \"update_block\"],\n",
    "  },\n",
    "  jira: {\n",
    "    tools: 16,\n",
    "    avgTokensPerTool: 820,\n",
    "    examples: [\"create_issue\", \"search_issues\", \"update_status\"],\n",
    "  },\n",
    "  serena: {\n",
    "    tools: 25,\n",
    "    avgTokensPerTool: 650,\n",
    "    examples: [\"analyze_code\", \"find_references\", \"rename_symbol\"],\n",
    "  },\n",
    "};\n",
    "\n",
    "// Calculate total context consumption\n",
    "const CONTEXT_WINDOW = 200_000; // Claude's context window\n",
    "\n",
    "let totalTokens = 0;\n",
    "let totalTools = 0;\n",
    "\n",
    "console.log(\"MCP Server Context Consumption\\n\" + \"=\".repeat(50));\n",
    "console.log();\n",
    "\n",
    "for (const [server, data] of Object.entries(mcpServers)) {\n",
    "  const serverTokens = data.tools * data.avgTokensPerTool;\n",
    "  totalTokens += serverTokens;\n",
    "  totalTools += data.tools;\n",
    "\n",
    "  const percentage = ((serverTokens / CONTEXT_WINDOW) * 100).toFixed(1);\n",
    "  console.log(\n",
    "    `${server.padEnd(12)} ${\n",
    "      data.tools.toString().padStart(2)\n",
    "    } tools Ã— ${data.avgTokensPerTool} tokens = ${\n",
    "      serverTokens.toLocaleString().padStart(6)\n",
    "    } tokens (${percentage}%)`,\n",
    "  );\n",
    "}\n",
    "\n",
    "console.log(\"â”€\".repeat(50));\n",
    "const totalPercentage = ((totalTokens / CONTEXT_WINDOW) * 100).toFixed(1);\n",
    "console.log(\n",
    "  `TOTAL:       ${totalTools} tools                   ${\n",
    "    totalTokens.toLocaleString().padStart(6)\n",
    "  } tokens (${totalPercentage}%)`,\n",
    ");\n",
    "console.log();\n",
    "console.log(\n",
    "  `âš ï¸  ${totalPercentage}% of your context window is consumed BEFORE you even start talking!`,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### The Impact\n",
    "\n",
    "With ~45% of context consumed by tool schemas:\n",
    "\n",
    "- **Long conversations get truncated** - Important context gets dropped\n",
    "- **Complex tasks fail** - Not enough room for reasoning\n",
    "- **You self-limit** - \"I'll disable that MCP server to save context\"\n",
    "\n",
    "And here's the irony: **You only use 3-5 tools per request**, but you're paying for 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Waste Problem\n",
      "==================================================\n",
      "\n",
      "Context Window Usage:\n",
      "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 45% consumed by tool schemas\n",
      "\n",
      "ğŸ“Š Token Efficiency Analysis:\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Metric   â”‚       Loaded â”‚ Actually Used â”‚            Delta\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Tokens   â”‚       90,870 â”‚        3,029 â”‚  -87841 (-96.7%)\n",
      "Tools    â”‚          120 â”‚            4 â”‚    -116 (-96.7%)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ’¸ You're paying for 116 tools you don't use!\n",
      "ğŸ“‰ 43.9% of your context window is wasted!\n"
     ]
    }
   ],
   "source": [
    "// The waste calculation - now with visual metrics\n",
    "import { progressBar, compareMetrics } from \"../lib/metrics.ts\";\n",
    "\n",
    "const TOOLS_USED_PER_REQUEST = 4; // Average tools actually used\n",
    "// Use dynamic totalTools from previous cell instead of hardcoding\n",
    "const tokensUsed = TOOLS_USED_PER_REQUEST * (totalTokens / totalTools);\n",
    "\n",
    "const usageRate = (TOOLS_USED_PER_REQUEST / totalTools * 100).toFixed(1);\n",
    "const wastedTokens = totalTokens * (1 - TOOLS_USED_PER_REQUEST / totalTools);\n",
    "const wastedPercentage = (wastedTokens / CONTEXT_WINDOW * 100).toFixed(1);\n",
    "\n",
    "console.log(\"The Waste Problem\\n\" + \"=\".repeat(50));\n",
    "console.log();\n",
    "\n",
    "// Visual progress bar showing context consumption\n",
    "console.log(\"Context Window Usage:\");\n",
    "console.log(progressBar(totalTokens, CONTEXT_WINDOW, \"consumed by tool schemas\"));\n",
    "console.log();\n",
    "\n",
    "// Comparison table: loaded vs used\n",
    "console.log(\"ğŸ“Š Token Efficiency Analysis:\\n\");\n",
    "console.log(compareMetrics(\n",
    "  { \"Tokens\": totalTokens, \"Tools\": totalTools },\n",
    "  { \"Tokens\": Math.round(tokensUsed), \"Tools\": TOOLS_USED_PER_REQUEST },\n",
    "  { labels: { before: \"Loaded\", after: \"Actually Used\" } }\n",
    "));\n",
    "console.log();\n",
    "\n",
    "console.log(`ğŸ’¸ You're paying for ${totalTools - TOOLS_USED_PER_REQUEST} tools you don't use!`);\n",
    "console.log(`ğŸ“‰ ${wastedPercentage}% of your context window is wasted!`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problem 2: Sequential Latency\n",
    "\n",
    "Now let's look at the second problem: **every tool call is sequential**.\n",
    "\n",
    "Consider a simple workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow: Create Jira ticket from config + GitHub + Slack\n",
      "\n",
      "Note: Steps 3 and 4 are INDEPENDENT - they could run in parallel!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg aria-roledescription=\"flowchart-v2\" role=\"graphics-document document\" viewBox=\"0 0 1206 222\" height=\"222\" class=\"flowchart\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1206\" id=\"container\"><style>#container{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#container .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#container .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#container .error-icon{fill:#552222;}#container .error-text{fill:#552222;stroke:#552222;}#container .edge-thickness-normal{stroke-width:1px;}#container .edge-thickness-thick{stroke-width:3.5px;}#container .edge-pattern-solid{stroke-dasharray:0;}#container .edge-thickness-invisible{stroke-width:0;fill:none;}#container .edge-pattern-dashed{stroke-dasharray:3;}#container .edge-pattern-dotted{stroke-dasharray:2;}#container .marker{fill:#333333;stroke:#333333;}#container .marker.cross{stroke:#333333;}#container svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#container p{margin:0;}#container .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#container .cluster-label text{fill:#333;}#container .cluster-label span{color:#333;}#container .cluster-label span p{background-color:transparent;}#container .label text,#container span{fill:#333;color:#333;}#container .node rect,#container .node circle,#container .node ellipse,#container .node polygon,#container .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#container .rough-node .label text,#container .node .label text,#container .image-shape .label,#container .icon-shape .label{text-anchor:middle;}#container .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#container .rough-node .label,#container .node .label,#container .image-shape .label,#container .icon-shape .label{text-align:center;}#container .node.clickable{cursor:pointer;}#container .root .anchor path{fill:#333333!important;stroke-width:0;stroke:#333333;}#container .arrowheadPath{fill:#333333;}#container .edgePath .path{stroke:#333333;stroke-width:2.0px;}#container .flowchart-link{stroke:#333333;fill:none;}#container .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#container .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#container .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#container .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#container .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#container .cluster text{fill:#333;}#container .cluster span{color:#333;}#container div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#container .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#container rect.text{fill:none;stroke-width:0;}#container .icon-shape,#container .image-shape{background-color:rgba(232,232,232, 0.8);text-align:center;}#container .icon-shape p,#container .image-shape p{background-color:rgba(232,232,232, 0.8);padding:2px;}#container .icon-shape rect,#container .image-shape rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#container :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g><marker orient=\"auto\" markerHeight=\"8\" markerWidth=\"8\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"5\" viewBox=\"0 0 10 10\" class=\"marker flowchart-v2\" id=\"container_flowchart-v2-pointEnd\"><path style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 0 0 L 10 5 L 0 10 z\"></path></marker><marker orient=\"auto\" markerHeight=\"8\" markerWidth=\"8\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"4.5\" viewBox=\"0 0 10 10\" class=\"marker flowchart-v2\" id=\"container_flowchart-v2-pointStart\"><path style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 0 5 L 10 10 L 10 0 z\"></path></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"11\" viewBox=\"0 0 10 10\" class=\"marker flowchart-v2\" id=\"container_flowchart-v2-circleEnd\"><circle style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" r=\"5\" cy=\"5\" cx=\"5\"></circle></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"-1\" viewBox=\"0 0 10 10\" class=\"marker flowchart-v2\" id=\"container_flowchart-v2-circleStart\"><circle style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" r=\"5\" cy=\"5\" cx=\"5\"></circle></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5.2\" refX=\"12\" viewBox=\"0 0 11 11\" class=\"marker cross flowchart-v2\" id=\"container_flowchart-v2-crossEnd\"><path style=\"stroke-width: 2; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 1,1 l 9,9 M 10,1 l -9,9\"></path></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5.2\" refX=\"-1\" viewBox=\"0 0 11 11\" class=\"marker cross flowchart-v2\" id=\"container_flowchart-v2-crossStart\"><path style=\"stroke-width: 2; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 1,1 l 9,9 M 10,1 l -9,9\"></path></marker><g class=\"root\"><g class=\"clusters\"></g><g class=\"edgePaths\"><path marker-end=\"url(#container_flowchart-v2-pointEnd)\" style=\"\" class=\"edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" id=\"L_A_B_0\" d=\"M268,111L272.167,111C276.333,111,284.667,111,292.333,111C300,111,307,111,310.5,111L314,111\"></path><path marker-end=\"url(#container_flowchart-v2-pointEnd)\" style=\"\" class=\"edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" id=\"L_B_C_0\" d=\"M542.453,72L552.544,67.833C562.635,63.667,582.818,55.333,596.409,51.167C610,47,617,47,620.5,47L624,47\"></path><path marker-end=\"url(#container_flowchart-v2-pointEnd)\" style=\"\" class=\"edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" id=\"L_B_D_0\" d=\"M542.453,150L552.544,154.167C562.635,158.333,582.818,166.667,596.409,170.833C610,175,617,175,620.5,175L624,175\"></path><path marker-end=\"url(#container_flowchart-v2-pointEnd)\" style=\"\" class=\"edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" id=\"L_C_E_0\" d=\"M888,47L892.167,47C896.333,47,904.667,47,918.308,50.912C931.95,54.824,950.9,62.649,960.375,66.561L969.85,70.473\"></path><path marker-end=\"url(#container_flowchart-v2-pointEnd)\" style=\"\" class=\"edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" id=\"L_D_E_0\" d=\"M888,175L892.167,175C896.333,175,904.667,175,918.308,171.088C931.95,167.176,950.9,159.351,960.375,155.439L969.85,151.527\"></path></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\" class=\"labelBkg\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\" class=\"labelBkg\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\" class=\"labelBkg\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\" class=\"labelBkg\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\" class=\"labelBkg\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g transform=\"translate(138, 111)\" id=\"flowchart-A-0\" class=\"node default\"><rect height=\"78\" width=\"260\" y=\"-39\" x=\"-130\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-100, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"200\"><div style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Unsupported markdown: list</span></div></foreignObject></g></g><g transform=\"translate(448, 111)\" id=\"flowchart-B-1\" class=\"node default\"><rect height=\"78\" width=\"260\" y=\"-39\" x=\"-130\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-100, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"200\"><div style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Unsupported markdown: list</span></div></foreignObject></g></g><g transform=\"translate(758, 47)\" id=\"flowchart-C-3\" class=\"node default\"><rect height=\"78\" width=\"260\" y=\"-39\" x=\"-130\" style=\"fill:#9cf !important;stroke:#333 !important\" class=\"basic label-container\"></rect><g transform=\"translate(-100, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"200\"><div style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Unsupported markdown: list</span></div></foreignObject></g></g><g transform=\"translate(758, 175)\" id=\"flowchart-D-5\" class=\"node default\"><rect height=\"78\" width=\"260\" y=\"-39\" x=\"-130\" style=\"fill:#9cf !important;stroke:#333 !important\" class=\"basic label-container\"></rect><g transform=\"translate(-100, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"200\"><div style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Unsupported markdown: list</span></div></foreignObject></g></g><g transform=\"translate(1068, 111)\" id=\"flowchart-E-7\" class=\"node default\"><rect height=\"78\" width=\"260\" y=\"-39\" x=\"-130\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-100, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"200\"><div style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Unsupported markdown: list</span></div></foreignObject></g></g></g></g></g></svg>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Simulate a multi-tool workflow\n",
    "import { displayMermaid } from \"../lib/viz.ts\";\n",
    "\n",
    "interface Task {\n",
    "  name: string;\n",
    "  duration: number; // ms\n",
    "  dependsOn: string[];\n",
    "}\n",
    "\n",
    "const workflow: Task[] = [\n",
    "  { name: \"1. Read config file\", duration: 200, dependsOn: [] },\n",
    "  { name: \"2. Parse JSON\", duration: 50, dependsOn: [\"1. Read config file\"] },\n",
    "  { name: \"3. Fetch GitHub issues\", duration: 800, dependsOn: [\"2. Parse JSON\"] },\n",
    "  { name: \"4. Search Slack messages\", duration: 600, dependsOn: [\"2. Parse JSON\"] },\n",
    "  {\n",
    "    name: \"5. Create Jira ticket\",\n",
    "    duration: 400,\n",
    "    dependsOn: [\"3. Fetch GitHub issues\", \"4. Search Slack messages\"],\n",
    "  },\n",
    "];\n",
    "\n",
    "console.log(\"Workflow: Create Jira ticket from config + GitHub + Slack\\n\");\n",
    "console.log(\"Note: Steps 3 and 4 are INDEPENDENT - they could run in parallel!\");\n",
    "console.log();\n",
    "\n",
    "// Visualize the DAG structure with Mermaid\n",
    "const dagDefinition = `graph LR\n",
    "    A[\"1. Read config<br/>200ms\"] --> B[\"2. Parse JSON<br/>50ms\"]\n",
    "    B --> C[\"3. Fetch GitHub<br/>800ms\"]\n",
    "    B --> D[\"4. Search Slack<br/>600ms\"]\n",
    "    C --> E[\"5. Create Jira<br/>400ms\"]\n",
    "    D --> E\n",
    "    \n",
    "    style C fill:#9cf,stroke:#333\n",
    "    style D fill:#9cf,stroke:#333`;\n",
    "\n",
    "await displayMermaid(dagDefinition);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Execution (Current MCP)\n",
      "=============================================\n",
      "1. Read config file       200ms (total: 200ms)\n",
      "2. Parse JSON             50ms (total: 250ms)\n",
      "3. Fetch GitHub issues    800ms (total: 1050ms)\n",
      "4. Search Slack messages  600ms (total: 1650ms)\n",
      "5. Create Jira ticket     400ms (total: 2050ms)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Total time: 2050ms\n"
     ]
    }
   ],
   "source": [
    "// Sequential execution (how MCP works today)\n",
    "async function executeSequentially(tasks: Task[]): Promise<number> {\n",
    "  let totalTime = 0;\n",
    "\n",
    "  console.log(\"Sequential Execution (Current MCP)\\n\" + \"=\".repeat(45));\n",
    "\n",
    "  for (const task of tasks) {\n",
    "    const start = Date.now();\n",
    "    await new Promise((r) => setTimeout(r, task.duration));\n",
    "    totalTime += task.duration;\n",
    "    console.log(`${task.name.padEnd(25)} ${task.duration}ms (total: ${totalTime}ms)`);\n",
    "  }\n",
    "\n",
    "  return totalTime;\n",
    "}\n",
    "\n",
    "const sequentialTime = await executeSequentially(workflow);\n",
    "console.log(\"â”€\".repeat(45));\n",
    "console.log(`Total time: ${sequentialTime}ms`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parallel Execution (With DAG)\n",
      "=============================================\n",
      "1. Read config file       200ms\n",
      "2. Parse JSON             50ms\n",
      "[PARALLEL] Running 2 tasks simultaneously:\n",
      "  â”œâ”€ 3. Fetch GitHub issues    800ms\n",
      "  â”œâ”€ 4. Search Slack messages  600ms\n",
      "  â””â”€ Layer complete at 1050ms\n",
      "5. Create Jira ticket     400ms\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Total time: 1450ms\n",
      "\n",
      "ğŸ“Š Performance Comparison:\n",
      "\n",
      "Sequential: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 2,050ms\n",
      "Parallel:   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1,450ms\n",
      "\n",
      "Speedup: 1.41x faster\n",
      "Time saved: 600ms (29%)\n"
     ]
    }
   ],
   "source": [
    "// Parallel execution (how it COULD work with DAG)\n",
    "import { speedupChart } from \"../lib/metrics.ts\";\n",
    "\n",
    "async function executeWithDAG(tasks: Task[]): Promise<number> {\n",
    "  const completed = new Map<string, number>();\n",
    "  let currentTime = 0;\n",
    "\n",
    "  console.log(\"\\nParallel Execution (With DAG)\\n\" + \"=\".repeat(45));\n",
    "\n",
    "  while (completed.size < tasks.length) {\n",
    "    // Find tasks that can run now (all dependencies satisfied)\n",
    "    const ready = tasks.filter((t) =>\n",
    "      !completed.has(t.name) &&\n",
    "      t.dependsOn.every((dep) => completed.has(dep))\n",
    "    );\n",
    "\n",
    "    if (ready.length === 0) break;\n",
    "\n",
    "    // Execute ready tasks in parallel\n",
    "    const startTime = currentTime;\n",
    "    const maxDuration = Math.max(...ready.map((t) => t.duration));\n",
    "\n",
    "    if (ready.length > 1) {\n",
    "      console.log(`[PARALLEL] Running ${ready.length} tasks simultaneously:`);\n",
    "    }\n",
    "\n",
    "    for (const task of ready) {\n",
    "      const endTime = startTime + task.duration;\n",
    "      completed.set(task.name, endTime);\n",
    "      const prefix = ready.length > 1 ? \"  â”œâ”€ \" : \"\";\n",
    "      console.log(`${prefix}${task.name.padEnd(25)} ${task.duration}ms`);\n",
    "    }\n",
    "\n",
    "    currentTime = startTime + maxDuration;\n",
    "\n",
    "    if (ready.length > 1) {\n",
    "      console.log(`  â””â”€ Layer complete at ${currentTime}ms`);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return currentTime;\n",
    "}\n",
    "\n",
    "const parallelTime = await executeWithDAG(workflow);\n",
    "console.log(\"â”€\".repeat(45));\n",
    "console.log(`Total time: ${parallelTime}ms`);\n",
    "console.log();\n",
    "\n",
    "// Visual speedup comparison chart\n",
    "console.log(\"ğŸ“Š Performance Comparison:\\n\");\n",
    "console.log(speedupChart(sequentialTime, parallelTime));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Real Cost\n",
    "\n",
    "Let's put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MCP Scaling Problem - Summary\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š CONTEXT WASTE\n",
      "   â€¢ 120 tools loaded, 4 used per request\n",
      "   â€¢ 45.4% of context consumed before you start\n",
      "   â€¢ Result: Shorter conversations, truncated responses\n",
      "\n",
      "â±ï¸  LATENCY COST\n",
      "   â€¢ Sequential: 2050ms\n",
      "   â€¢ Could be:   1450ms (1.4x faster)\n",
      "   â€¢ Result: Slow workflows, broken flow state\n",
      "\n",
      "ğŸš§ THE CONSEQUENCE\n",
      "   â€¢ Power users limit themselves to 7-8 MCP servers\n",
      "   â€¢ Complex cross-MCP workflows are impractical\n",
      "   â€¢ The MCP ecosystem can't reach its potential\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’¡ This is why Casys MCP Gateway exists.\n"
     ]
    }
   ],
   "source": [
    "// Calculate speedup for summary\n",
    "const speedup = (sequentialTime / parallelTime).toFixed(1);\n",
    "\n",
    "console.log(\"The MCP Scaling Problem - Summary\\n\" + \"=\".repeat(50));\n",
    "console.log();\n",
    "console.log(\"ğŸ“Š CONTEXT WASTE\");\n",
    "console.log(`   â€¢ ${totalTools} tools loaded, ${TOOLS_USED_PER_REQUEST} used per request`);\n",
    "console.log(`   â€¢ ${totalPercentage}% of context consumed before you start`);\n",
    "console.log(`   â€¢ Result: Shorter conversations, truncated responses`);\n",
    "console.log();\n",
    "console.log(\"â±ï¸  LATENCY COST\");\n",
    "console.log(`   â€¢ Sequential: ${sequentialTime}ms`);\n",
    "console.log(`   â€¢ Could be:   ${parallelTime}ms (${speedup}x faster)`);\n",
    "console.log(`   â€¢ Result: Slow workflows, broken flow state`);\n",
    "console.log();\n",
    "console.log(\"ğŸš§ THE CONSEQUENCE\");\n",
    "console.log(\"   â€¢ Power users limit themselves to 7-8 MCP servers\");\n",
    "console.log(\"   â€¢ Complex cross-MCP workflows are impractical\");\n",
    "console.log(\"   â€¢ The MCP ecosystem can't reach its potential\");\n",
    "console.log();\n",
    "console.log(\"â”€\".repeat(50));\n",
    "console.log(\"ğŸ’¡ This is why Casys MCP Gateway exists.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've now experienced the two core problems that limit MCP adoption:\n",
    "\n",
    "1. **Context Explosion** - Tool schemas consume ~45% of context before you start\n",
    "2. **Sequential Latency** - Independent tasks wait for each other unnecessarily\n",
    "\n",
    "These problems compound as you add more MCP servers, creating a ceiling on what's practical.\n",
    "\n",
    "**Next:** [02-context-optimization.ipynb](./02-context-optimization.ipynb) - Learn how vector search solves the context problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
