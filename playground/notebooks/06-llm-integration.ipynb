{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-LLM Integration Demo\n",
        "\n",
        "Test the MCP Gateway with OpenAI, Anthropic, or Google Gemini using your own API keys."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Your API Key\n",
        "\n",
        "Set your API key as an environment variable (choose one):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è  Uncomment and set your API key above before running!\n"
          ]
        }
      ],
      "source": [
        "// Option 1: Anthropic Claude\n",
        "// Deno.env.set(\"ANTHROPIC_API_KEY\", \"sk-ant-api03-...\");\n",
        "\n",
        "// Option 2: OpenAI GPT\n",
        "/Deno.env.set(\"OPENAI_API_KEY\", \"sk-...\");\n",
        "\n",
        "// Option 3: Google Gemini\n",
        "// Deno.env.set(\"GOOGLE_API_KEY\", \"AIza...\");\n",
        "\n",
        "console.log(\"‚ö†Ô∏è  Uncomment and set your API key above before running!\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import LLM Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import {\n",
        "  detectProvider,\n",
        "  generateCompletion,\n",
        "  getDefaultModel,\n",
        "} from \"../examples/lib/llm-provider.ts\";\n",
        "\n",
        "const apiKey = Deno.env.get(\"ANTHROPIC_API_KEY\") ||\n",
        "  Deno.env.get(\"OPENAI_API_KEY\") ||\n",
        "  Deno.env.get(\"GOOGLE_API_KEY\");\n",
        "\n",
        "if (!apiKey) {\n",
        "  throw new Error(\"No API key found! Set one in the cell above.\");\n",
        "}\n",
        "\n",
        "const provider = detectProvider(apiKey);\n",
        "const model = getDefaultModel(provider);\n",
        "\n",
        "console.log(`‚úÖ Provider: ${provider}`);\n",
        "console.log(`   Model: ${model}`);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 1: Simple Completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const result = await generateCompletion(\n",
        "  { apiKey },\n",
        "  \"Explain what a code sandbox is in one sentence.\",\n",
        ");\n",
        "\n",
        "console.log(\"Response:\", result.text);\n",
        "console.log(\"\\nTokens used:\", result.usage.totalTokens);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 2: Code Generation with Sandbox\n",
        "\n",
        "Use LLM to generate code, then execute it safely in sandbox:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import { DenoSandboxExecutor } from \"jsr:@casys/mcp-gateway\";\n",
        "\n",
        "const sandbox = new DenoSandboxExecutor({ timeout: 5000 });\n",
        "\n",
        "// Ask LLM to generate code\n",
        "const codeGenResult = await generateCompletion(\n",
        "  { apiKey },\n",
        "  \"Write TypeScript code that calculates fibonacci(10). Return only the code, no explanation.\",\n",
        "  { temperature: 0.3 },\n",
        ");\n",
        "\n",
        "console.log(\"Generated code:\");\n",
        "console.log(codeGenResult.text);\n",
        "\n",
        "// Execute the generated code safely\n",
        "console.log(\"\\nExecuting in sandbox...\");\n",
        "const execResult = await sandbox.execute(codeGenResult.text);\n",
        "\n",
        "if (execResult.success) {\n",
        "  console.log(\"‚úÖ Result:\", execResult.result);\n",
        "} else {\n",
        "  console.log(\"‚ùå Error:\", execResult.error);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 3: Data Analysis Assistant\n",
        "\n",
        "LLM analyzes data, generates transformation code, sandbox executes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const salesData = [\n",
        "  { product: \"Laptop\", revenue: 2400, units: 2 },\n",
        "  { product: \"Mouse\", revenue: 125, units: 5 },\n",
        "  { product: \"Keyboard\", revenue: 240, units: 3 },\n",
        "];\n",
        "\n",
        "// Ask LLM to generate analysis code\n",
        "const prompt = `Given this sales data:\n",
        "${JSON.stringify(salesData, null, 2)}\n",
        "\n",
        "Write TypeScript code that:\n",
        "1. Calculates total revenue\n",
        "2. Finds the best-selling product by revenue\n",
        "3. Returns { totalRevenue, bestProduct, avgPrice }\n",
        "\n",
        "The data is available in context.salesData. Return only code.`;\n",
        "\n",
        "const codeResult = await generateCompletion(\n",
        "  { apiKey },\n",
        "  prompt,\n",
        "  { temperature: 0.2 },\n",
        ");\n",
        "\n",
        "console.log(\"LLM generated code:\");\n",
        "console.log(codeResult.text);\n",
        "\n",
        "// Execute with actual data\n",
        "const analysisResult = await sandbox.execute(\n",
        "  codeResult.text,\n",
        "  { salesData },\n",
        ");\n",
        "\n",
        "console.log(\"\\nüìä Analysis Results:\");\n",
        "console.log(JSON.stringify(analysisResult.result, null, 2));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 4: Compare Providers\n",
        "\n",
        "If you have multiple API keys, compare responses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "const providers = [\n",
        "  { name: \"Anthropic\", key: Deno.env.get(\"ANTHROPIC_API_KEY\") },\n",
        "  { name: \"OpenAI\", key: Deno.env.get(\"OPENAI_API_KEY\") },\n",
        "  { name: \"Google\", key: Deno.env.get(\"GOOGLE_API_KEY\") },\n",
        "].filter((p) => p.key);\n",
        "\n",
        "if (providers.length === 0) {\n",
        "  console.log(\"‚ö†Ô∏è  Set multiple API keys to compare providers\");\n",
        "} else {\n",
        "  const prompt = \"What is 2+2? Answer in 5 words or less.\";\n",
        "\n",
        "  console.log(`Testing ${providers.length} provider(s):\\n`);\n",
        "\n",
        "  for (const provider of providers) {\n",
        "    console.log(`ü§ñ ${provider.name}:`);\n",
        "    const result = await generateCompletion(\n",
        "      { apiKey: provider.key! },\n",
        "      prompt,\n",
        "    );\n",
        "    console.log(`   Response: ${result.text}`);\n",
        "    console.log(`   Tokens: ${result.usage.totalTokens}\\n`);\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "You can now:\n",
        "\n",
        "- ‚úÖ Use **any LLM** (OpenAI, Anthropic, Google) with your own keys\n",
        "- ‚úÖ Generate code with LLMs and execute safely in sandbox\n",
        "- ‚úÖ Build AI-powered data analysis pipelines\n",
        "- ‚úÖ Compare different providers\n",
        "\n",
        "**Provider auto-detection:**\n",
        "\n",
        "- `sk-ant-...` ‚Üí Anthropic Claude\n",
        "- `sk-...` ‚Üí OpenAI GPT\n",
        "- `AIza...` ‚Üí Google Gemini"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Deno",
      "language": "typescript",
      "name": "deno"
    },
    "language_info": {
      "codemirror_mode": "typescript",
      "file_extension": ".ts",
      "mimetype": "text/x.typescript",
      "name": "typescript",
      "nbconvert_exporter": "script",
      "pygments_lexer": "typescript",
      "version": "5.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
